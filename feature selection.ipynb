{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/jupyter/env3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/ian/jupyter/env3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_imperson_without4n7_balanced_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete columns that have zero variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_delete = [k for k in train.columns if train[k].std()==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of which there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(col_to_delete,axis=1)\n",
    "trainX = train[train.columns[:-1]]\n",
    "trainY = train[\"155\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX0 = trainX[trainY==0]\n",
    "trainX1 = trainX[trainY>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97044"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a data table to hold information regarding the remaining variables\n",
    "\n",
    "(Some `pandas` operations are easier if the factor name is a regular column but it's nice for that to be the index too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = pd.DataFrame(data = trainX.columns, columns = ['factor'], index = train.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>mu0</th>\n",
       "      <th>mu1</th>\n",
       "      <th>sigma0</th>\n",
       "      <th>sigma1</th>\n",
       "      <th>rho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005345</td>\n",
       "      <td>0.007160</td>\n",
       "      <td>0.018728</td>\n",
       "      <td>0.011431</td>\n",
       "      <td>0.058410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005345</td>\n",
       "      <td>0.007160</td>\n",
       "      <td>0.018728</td>\n",
       "      <td>0.011431</td>\n",
       "      <td>0.058410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.349147</td>\n",
       "      <td>0.038526</td>\n",
       "      <td>0.450527</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>-0.438183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.349147</td>\n",
       "      <td>0.038526</td>\n",
       "      <td>0.450527</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>-0.438183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.999567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   factor       mu0       mu1    sigma0    sigma1       rho\n",
       "5       5  0.005345  0.007160  0.018728  0.011431  0.058410\n",
       "6       6  0.005345  0.007160  0.018728  0.011431  0.058410\n",
       "8       8  0.349147  0.038526  0.450527  0.006735 -0.438183\n",
       "9       9  0.349147  0.038526  0.450527  0.006735 -0.438183\n",
       "14     14  0.999567  1.000000  0.020799  0.000000  0.014712"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors[\"mu0\"] = factors.factor.apply(lambda f: trainX0[f].mean())\n",
    "factors[\"mu1\"] = factors.factor.apply(lambda f: trainX1[f].mean())\n",
    "\n",
    "factors[\"sigma0\"] = factors.factor.apply(lambda f: trainX0[f].std())\n",
    "factors[\"sigma1\"] = factors.factor.apply(lambda f: trainX1[f].std())\n",
    "\n",
    "factors[\"rho\"] = factors.factor.apply(lambda f: train[f].corr(train[\"155\"]))\n",
    "\n",
    "factors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting factors by the absolute value of $\\rho$, since a negative correlation is as predictive as a postive one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors[\"absrho\"]=abs(factors[\"rho\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>mu0</th>\n",
       "      <th>mu1</th>\n",
       "      <th>sigma0</th>\n",
       "      <th>sigma1</th>\n",
       "      <th>rho</th>\n",
       "      <th>absrho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>7.086695e-01</td>\n",
       "      <td>0.045289</td>\n",
       "      <td>0.260226</td>\n",
       "      <td>0.157740</td>\n",
       "      <td>-0.838937</td>\n",
       "      <td>0.838937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>4.843164e-03</td>\n",
       "      <td>0.676456</td>\n",
       "      <td>0.069425</td>\n",
       "      <td>0.467833</td>\n",
       "      <td>0.708561</td>\n",
       "      <td>0.708561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>4.031573e-01</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.490537</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>0.652165</td>\n",
       "      <td>0.652165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>5.964099e-01</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.490622</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>-0.651828</td>\n",
       "      <td>0.651828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>5.018176e-01</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.450187</td>\n",
       "      <td>0.004542</td>\n",
       "      <td>-0.618997</td>\n",
       "      <td>0.618997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>4.490540e-01</td>\n",
       "      <td>0.921829</td>\n",
       "      <td>0.470411</td>\n",
       "      <td>0.268404</td>\n",
       "      <td>0.525254</td>\n",
       "      <td>0.525254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>6.591980e-01</td>\n",
       "      <td>0.768314</td>\n",
       "      <td>0.132439</td>\n",
       "      <td>0.024954</td>\n",
       "      <td>0.496848</td>\n",
       "      <td>0.496848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>3.597495e-01</td>\n",
       "      <td>0.091727</td>\n",
       "      <td>0.329202</td>\n",
       "      <td>0.055956</td>\n",
       "      <td>-0.493602</td>\n",
       "      <td>0.493602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>4.862330e-01</td>\n",
       "      <td>0.921870</td>\n",
       "      <td>0.499816</td>\n",
       "      <td>0.268378</td>\n",
       "      <td>0.477183</td>\n",
       "      <td>0.477183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>146</td>\n",
       "      <td>5.687225e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.453058</td>\n",
       "      <td>0.453058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>145</td>\n",
       "      <td>5.687225e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.453058</td>\n",
       "      <td>0.453058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>3.491472e-01</td>\n",
       "      <td>0.038526</td>\n",
       "      <td>0.450527</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>-0.438183</td>\n",
       "      <td>0.438183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>3.491472e-01</td>\n",
       "      <td>0.038526</td>\n",
       "      <td>0.450527</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>-0.438183</td>\n",
       "      <td>0.438183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>154</td>\n",
       "      <td>3.349401e-01</td>\n",
       "      <td>0.022008</td>\n",
       "      <td>0.458596</td>\n",
       "      <td>0.006407</td>\n",
       "      <td>-0.434536</td>\n",
       "      <td>0.434536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>6.336301e-01</td>\n",
       "      <td>0.921870</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.268378</td>\n",
       "      <td>0.385492</td>\n",
       "      <td>0.385492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>5.426613e-03</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.011442</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>-0.296245</td>\n",
       "      <td>0.296245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>1.506739e-01</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.357734</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>-0.285381</td>\n",
       "      <td>0.285381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>110</td>\n",
       "      <td>1.527235e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.256507</td>\n",
       "      <td>0.256507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>3.892950e-02</td>\n",
       "      <td>0.008852</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.038162</td>\n",
       "      <td>-0.201783</td>\n",
       "      <td>0.201783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>122</td>\n",
       "      <td>3.645072e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.182614</td>\n",
       "      <td>0.182614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>2.261501e-01</td>\n",
       "      <td>0.320148</td>\n",
       "      <td>0.301992</td>\n",
       "      <td>0.199302</td>\n",
       "      <td>0.180674</td>\n",
       "      <td>0.180674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>5.585095e-02</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.229636</td>\n",
       "      <td>0.016984</td>\n",
       "      <td>-0.168196</td>\n",
       "      <td>0.168196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107</td>\n",
       "      <td>4.734967e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.150600</td>\n",
       "      <td>0.150600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>130</td>\n",
       "      <td>4.307325e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.148360</td>\n",
       "      <td>0.148360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>6.633280e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.148360</td>\n",
       "      <td>0.148360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>129</td>\n",
       "      <td>6.805573e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.148360</td>\n",
       "      <td>0.148360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>127</td>\n",
       "      <td>3.379894e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.148324</td>\n",
       "      <td>0.148324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128</td>\n",
       "      <td>1.284308e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.147055</td>\n",
       "      <td>0.147055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>6.077220e-01</td>\n",
       "      <td>0.634935</td>\n",
       "      <td>0.146420</td>\n",
       "      <td>0.074405</td>\n",
       "      <td>0.116366</td>\n",
       "      <td>0.116366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>2.310503e-01</td>\n",
       "      <td>0.291817</td>\n",
       "      <td>0.317456</td>\n",
       "      <td>0.187557</td>\n",
       "      <td>0.115751</td>\n",
       "      <td>0.115751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>7.549768e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.104006</td>\n",
       "      <td>0.104006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    factor           mu0       mu1    sigma0    sigma1       rho    absrho\n",
       "67      67  7.086695e-01  0.045289  0.260226  0.157740 -0.838937  0.838937\n",
       "71      71  4.843164e-03  0.676456  0.069425  0.467833  0.708561  0.708561\n",
       "50      50  4.031573e-01  0.999979  0.490537  0.004540  0.652165  0.652165\n",
       "51      51  5.964099e-01  0.000021  0.490622  0.004540 -0.651828  0.651828\n",
       "47      47  5.018176e-01  0.000022  0.450187  0.004542 -0.618997  0.618997\n",
       "68      68  4.490540e-01  0.921829  0.470411  0.268404  0.525254  0.525254\n",
       "38      38  6.591980e-01  0.768314  0.132439  0.024954  0.496848  0.496848\n",
       "82      82  3.597495e-01  0.091727  0.329202  0.055956 -0.493602  0.493602\n",
       "73      73  4.862330e-01  0.921870  0.499816  0.268378  0.477183  0.477183\n",
       "146    146  5.687225e-02  0.000000  0.079131  0.000000 -0.453058  0.453058\n",
       "145    145  5.687225e-02  0.000000  0.079131  0.000000 -0.453058  0.453058\n",
       "8        8  3.491472e-01  0.038526  0.450527  0.006735 -0.438183  0.438183\n",
       "9        9  3.491472e-01  0.038526  0.450527  0.006735 -0.438183  0.438183\n",
       "154    154  3.349401e-01  0.022008  0.458596  0.006407 -0.434536  0.434536\n",
       "66      66  6.336301e-01  0.921870  0.407407  0.268378  0.385492  0.385492\n",
       "75      75  5.426613e-03  0.000290  0.011442  0.002490 -0.296245  0.296245\n",
       "70      70  1.506739e-01  0.000021  0.357734  0.004540 -0.285381  0.285381\n",
       "110    110  1.527235e-05  0.000000  0.000041  0.000000 -0.256507  0.256507\n",
       "77      77  3.892950e-02  0.008852  0.095921  0.038162 -0.201783  0.201783\n",
       "122    122  3.645072e-04  0.000000  0.001388  0.000000 -0.182614  0.182614\n",
       "140    140  2.261501e-01  0.320148  0.301992  0.199302  0.180674  0.180674\n",
       "94      94  5.585095e-02  0.000289  0.229636  0.016984 -0.168196  0.168196\n",
       "107    107  4.734967e-03  0.000000  0.021979  0.000000 -0.150600  0.150600\n",
       "130    130  4.307325e-02  0.000000  0.203024  0.000000 -0.148360  0.148360\n",
       "126    126  6.633280e-07  0.000000  0.000003  0.000000 -0.148360  0.148360\n",
       "129    129  6.805573e-07  0.000000  0.000003  0.000000 -0.148360  0.148360\n",
       "127    127  3.379894e-04  0.000000  0.001593  0.000000 -0.148324  0.148324\n",
       "128    128  1.284308e-06  0.000000  0.000006  0.000000 -0.147055  0.147055\n",
       "61      61  6.077220e-01  0.634935  0.146420  0.074405  0.116366  0.116366\n",
       "142    142  2.310503e-01  0.291817  0.317456  0.187557  0.115751  0.115751\n",
       "141    141  7.549768e-03  0.000000  0.051051  0.000000 -0.104006  0.104006"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors.sort_values(by=\"absrho\", ascending=False).loc[factors[\"absrho\"]>0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-tests establish the probability $p$ that we see a least that difference in the mean of a factor for the two conditions under the null hypothesis that they come from the same distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>mu0</th>\n",
       "      <th>mu1</th>\n",
       "      <th>sigma0</th>\n",
       "      <th>sigma1</th>\n",
       "      <th>rho</th>\n",
       "      <th>absrho</th>\n",
       "      <th>t-test p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005345</td>\n",
       "      <td>0.007160</td>\n",
       "      <td>0.018728</td>\n",
       "      <td>0.011431</td>\n",
       "      <td>0.058410</td>\n",
       "      <td>0.058410</td>\n",
       "      <td>4.460255e-74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005345</td>\n",
       "      <td>0.007160</td>\n",
       "      <td>0.018728</td>\n",
       "      <td>0.011431</td>\n",
       "      <td>0.058410</td>\n",
       "      <td>0.058410</td>\n",
       "      <td>4.460255e-74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.349147</td>\n",
       "      <td>0.038526</td>\n",
       "      <td>0.450527</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>-0.438183</td>\n",
       "      <td>0.438183</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.349147</td>\n",
       "      <td>0.038526</td>\n",
       "      <td>0.450527</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>-0.438183</td>\n",
       "      <td>0.438183</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.999567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>4.583503e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   factor       mu0       mu1    sigma0    sigma1       rho    absrho  \\\n",
       "5       5  0.005345  0.007160  0.018728  0.011431  0.058410  0.058410   \n",
       "6       6  0.005345  0.007160  0.018728  0.011431  0.058410  0.058410   \n",
       "8       8  0.349147  0.038526  0.450527  0.006735 -0.438183  0.438183   \n",
       "9       9  0.349147  0.038526  0.450527  0.006735 -0.438183  0.438183   \n",
       "14     14  0.999567  1.000000  0.020799  0.000000  0.014712  0.014712   \n",
       "\n",
       "        t-test p  \n",
       "5   4.460255e-74  \n",
       "6   4.460255e-74  \n",
       "8   0.000000e+00  \n",
       "9   0.000000e+00  \n",
       "14  4.583503e-06  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors[\"t-test p\"] = factors.factor.apply(\n",
    "    lambda f: ttest_ind(trainX0[f],\n",
    "                        trainX1[f],\n",
    "                        equal_var=False)[1]\n",
    ")\n",
    "factors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort from lowest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>mu0</th>\n",
       "      <th>mu1</th>\n",
       "      <th>sigma0</th>\n",
       "      <th>sigma1</th>\n",
       "      <th>rho</th>\n",
       "      <th>absrho</th>\n",
       "      <th>t-test p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>154</td>\n",
       "      <td>0.334940</td>\n",
       "      <td>0.022008</td>\n",
       "      <td>0.458596</td>\n",
       "      <td>0.006407</td>\n",
       "      <td>-0.434536</td>\n",
       "      <td>0.434536</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>0.055851</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.229636</td>\n",
       "      <td>0.016984</td>\n",
       "      <td>-0.168196</td>\n",
       "      <td>0.168196</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>0.038930</td>\n",
       "      <td>0.008852</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.038162</td>\n",
       "      <td>-0.201783</td>\n",
       "      <td>0.201783</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>0.005427</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.011442</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>-0.296245</td>\n",
       "      <td>0.296245</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>0.486233</td>\n",
       "      <td>0.921870</td>\n",
       "      <td>0.499816</td>\n",
       "      <td>0.268378</td>\n",
       "      <td>0.477183</td>\n",
       "      <td>0.477183</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005242</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>0.102471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004540</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>0.157301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "      <td>0.500008</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003210</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>0.317315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>133</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003210</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>0.317315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003210</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>0.317315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    factor       mu0       mu1    sigma0    sigma1       rho    absrho  \\\n",
       "154    154  0.334940  0.022008  0.458596  0.006407 -0.434536  0.434536   \n",
       "94      94  0.055851  0.000289  0.229636  0.016984 -0.168196  0.168196   \n",
       "77      77  0.038930  0.008852  0.095921  0.038162 -0.201783  0.201783   \n",
       "75      75  0.005427  0.000290  0.011442  0.002490 -0.296245  0.296245   \n",
       "73      73  0.486233  0.921870  0.499816  0.268378  0.477183  0.477183   \n",
       "..     ...       ...       ...       ...       ...       ...       ...   \n",
       "105    105  0.000021  0.000000  0.002780  0.000000 -0.005242  0.005242   \n",
       "83      83  0.000041  0.000000  0.006420  0.000000 -0.004540  0.004540   \n",
       "138    138  0.500008  0.500000  0.001725  0.000000 -0.003210  0.003210   \n",
       "133    133  0.000021  0.000000  0.004540  0.000000 -0.003210  0.003210   \n",
       "97      97  0.000021  0.000000  0.004540  0.000000 -0.003210  0.003210   \n",
       "\n",
       "     t-test p  \n",
       "154  0.000000  \n",
       "94   0.000000  \n",
       "77   0.000000  \n",
       "75   0.000000  \n",
       "73   0.000000  \n",
       "..        ...  \n",
       "105  0.102471  \n",
       "83   0.157301  \n",
       "138  0.317315  \n",
       "133  0.317315  \n",
       "97   0.317315  \n",
       "\n",
       "[78 rows x 8 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors.sort_values(by=\"t-test p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many factors have $p<0.05$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(factors[factors[\"t-test p\"] < 0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p<0.000000001$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(factors[factors[\"t-test p\"] < 0.000000001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So most of the factors have a significantly different mean under the two conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some factors appear to only have a few values, eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[\"133\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column to track the number of unique values a factor takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors[\"vals\"] = factors.factor.apply(lambda f: len(train[f].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>mu0</th>\n",
       "      <th>mu1</th>\n",
       "      <th>sigma0</th>\n",
       "      <th>sigma1</th>\n",
       "      <th>rho</th>\n",
       "      <th>absrho</th>\n",
       "      <th>t-test p</th>\n",
       "      <th>vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>129</td>\n",
       "      <td>6.805573e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.148360</td>\n",
       "      <td>0.148360</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>1.482495e-03</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.035814</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>-0.028733</td>\n",
       "      <td>0.028733</td>\n",
       "      <td>3.530465e-19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>4.843164e-03</td>\n",
       "      <td>0.676456</td>\n",
       "      <td>0.069425</td>\n",
       "      <td>0.467833</td>\n",
       "      <td>0.708561</td>\n",
       "      <td>0.708561</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>1.978484e-03</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.044437</td>\n",
       "      <td>0.009079</td>\n",
       "      <td>-0.029548</td>\n",
       "      <td>0.029548</td>\n",
       "      <td>3.419408e-20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>4.862330e-01</td>\n",
       "      <td>0.921870</td>\n",
       "      <td>0.499816</td>\n",
       "      <td>0.268378</td>\n",
       "      <td>0.477183</td>\n",
       "      <td>0.477183</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>113</td>\n",
       "      <td>2.649747e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005560</td>\n",
       "      <td>0.005560</td>\n",
       "      <td>8.326452e-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>111</td>\n",
       "      <td>3.297473e-04</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.018156</td>\n",
       "      <td>0.024015</td>\n",
       "      <td>0.005809</td>\n",
       "      <td>0.005809</td>\n",
       "      <td>7.037820e-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>133</td>\n",
       "      <td>2.060921e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003210</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>3.173155e-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>4.121842e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004540</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>1.573013e-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>1.236552e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.007863</td>\n",
       "      <td>0.007863</td>\n",
       "      <td>1.430437e-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>1.648737e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009080</td>\n",
       "      <td>0.009080</td>\n",
       "      <td>4.676670e-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>9.995672e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>4.583503e-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>9.636866e-02</td>\n",
       "      <td>0.077305</td>\n",
       "      <td>0.295099</td>\n",
       "      <td>0.267078</td>\n",
       "      <td>-0.033849</td>\n",
       "      <td>0.033849</td>\n",
       "      <td>5.217817e-26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>6.535180e-02</td>\n",
       "      <td>0.041012</td>\n",
       "      <td>0.247148</td>\n",
       "      <td>0.198321</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>0.054233</td>\n",
       "      <td>4.042413e-64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>5.585095e-02</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.229636</td>\n",
       "      <td>0.016984</td>\n",
       "      <td>-0.168196</td>\n",
       "      <td>0.168196</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>2.060921e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003210</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>3.173155e-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>9.408104e-02</td>\n",
       "      <td>0.077305</td>\n",
       "      <td>0.291944</td>\n",
       "      <td>0.267078</td>\n",
       "      <td>-0.029967</td>\n",
       "      <td>0.029967</td>\n",
       "      <td>9.900238e-21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>108</td>\n",
       "      <td>1.250960e-04</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>-0.008767</td>\n",
       "      <td>0.008767</td>\n",
       "      <td>6.312788e-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>1.021598e-01</td>\n",
       "      <td>0.077965</td>\n",
       "      <td>0.302862</td>\n",
       "      <td>0.268119</td>\n",
       "      <td>-0.042259</td>\n",
       "      <td>0.042259</td>\n",
       "      <td>1.302655e-39</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>121</td>\n",
       "      <td>4.253581e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.068407</td>\n",
       "      <td>0.068407</td>\n",
       "      <td>9.223437e-101</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>1.506739e-01</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.357734</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>-0.285381</td>\n",
       "      <td>0.285381</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "      <td>5.000078e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003210</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>3.173155e-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>6.633280e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.148360</td>\n",
       "      <td>0.148360</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>9.995672e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>4.583503e-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>9.995672e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>4.583503e-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>9.995672e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>4.583503e-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>9.995672e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>4.583503e-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>9.995672e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>4.583503e-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>9.995672e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>4.583503e-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>9.995672e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>4.583503e-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>9.995672e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>4.583503e-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>130</td>\n",
       "      <td>4.307325e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.148360</td>\n",
       "      <td>0.148360</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>5.964099e-01</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.490622</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>-0.651828</td>\n",
       "      <td>0.651828</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>9.995672e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>4.583503e-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>123</td>\n",
       "      <td>1.236552e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.024873</td>\n",
       "      <td>0.024873</td>\n",
       "      <td>9.317263e-15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>4.031573e-01</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.490537</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>0.652165</td>\n",
       "      <td>0.652165</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>9.995672e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>4.583503e-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>2.060921e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005242</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>1.024710e-01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>145</td>\n",
       "      <td>5.687225e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.453058</td>\n",
       "      <td>0.453058</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>127</td>\n",
       "      <td>3.379894e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.148324</td>\n",
       "      <td>0.148324</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    factor           mu0       mu1    sigma0    sigma1       rho    absrho  \\\n",
       "129    129  6.805573e-07  0.000000  0.000003  0.000000 -0.148360  0.148360   \n",
       "106    106  1.482495e-03  0.000018  0.035814  0.003934 -0.028733  0.028733   \n",
       "71      71  4.843164e-03  0.676456  0.069425  0.467833  0.708561  0.708561   \n",
       "72      72  1.978484e-03  0.000082  0.044437  0.009079 -0.029548  0.029548   \n",
       "73      73  4.862330e-01  0.921870  0.499816  0.268378  0.477183  0.477183   \n",
       "113    113  2.649747e-05  0.000000  0.003370  0.000000 -0.005560  0.005560   \n",
       "111    111  3.297473e-04  0.000577  0.018156  0.024015  0.005809  0.005809   \n",
       "133    133  2.060921e-05  0.000000  0.004540  0.000000 -0.003210  0.003210   \n",
       "83      83  4.121842e-05  0.000000  0.006420  0.000000 -0.004540  0.004540   \n",
       "84      84  1.236552e-04  0.000000  0.011119  0.000000 -0.007863  0.007863   \n",
       "86      86  1.648737e-04  0.000000  0.012839  0.000000 -0.009080  0.009080   \n",
       "89      89  9.995672e-01  1.000000  0.020799  0.000000  0.014712  0.014712   \n",
       "90      90  9.636866e-02  0.077305  0.295099  0.267078 -0.033849  0.033849   \n",
       "93      93  6.535180e-02  0.041012  0.247148  0.198321 -0.054233  0.054233   \n",
       "94      94  5.585095e-02  0.000289  0.229636  0.016984 -0.168196  0.168196   \n",
       "97      97  2.060921e-05  0.000000  0.004540  0.000000 -0.003210  0.003210   \n",
       "98      98  9.408104e-02  0.077305  0.291944  0.267078 -0.029967  0.029967   \n",
       "108    108  1.250960e-04  0.000118  0.000419  0.000408 -0.008767  0.008767   \n",
       "118    118  1.021598e-01  0.077965  0.302862  0.268119 -0.042259  0.042259   \n",
       "121    121  4.253581e-05  0.000000  0.000439  0.000000 -0.068407  0.068407   \n",
       "70      70  1.506739e-01  0.000021  0.357734  0.004540 -0.285381  0.285381   \n",
       "138    138  5.000078e-01  0.500000  0.001725  0.000000 -0.003210  0.003210   \n",
       "126    126  6.633280e-07  0.000000  0.000003  0.000000 -0.148360  0.148360   \n",
       "14      14  9.995672e-01  1.000000  0.020799  0.000000  0.014712  0.014712   \n",
       "15      15  9.995672e-01  1.000000  0.020799  0.000000  0.014712  0.014712   \n",
       "16      16  9.995672e-01  1.000000  0.020799  0.000000  0.014712  0.014712   \n",
       "18      18  9.995672e-01  1.000000  0.020799  0.000000  0.014712  0.014712   \n",
       "20      20  9.995672e-01  1.000000  0.020799  0.000000  0.014712  0.014712   \n",
       "26      26  9.995672e-01  1.000000  0.020799  0.000000  0.014712  0.014712   \n",
       "29      29  9.995672e-01  1.000000  0.020799  0.000000  0.014712  0.014712   \n",
       "62      62  9.995672e-01  1.000000  0.020799  0.000000  0.014712  0.014712   \n",
       "130    130  4.307325e-02  0.000000  0.203024  0.000000 -0.148360  0.148360   \n",
       "51      51  5.964099e-01  0.000021  0.490622  0.004540 -0.651828  0.651828   \n",
       "43      43  9.995672e-01  1.000000  0.020799  0.000000  0.014712  0.014712   \n",
       "123    123  1.236552e-03  0.000000  0.035143  0.000000 -0.024873  0.024873   \n",
       "50      50  4.031573e-01  0.999979  0.490537  0.004540  0.652165  0.652165   \n",
       "52      52  9.995672e-01  1.000000  0.020799  0.000000  0.014712  0.014712   \n",
       "105    105  2.060921e-05  0.000000  0.002780  0.000000 -0.005242  0.005242   \n",
       "145    145  5.687225e-02  0.000000  0.079131  0.000000 -0.453058  0.453058   \n",
       "127    127  3.379894e-04  0.000000  0.001593  0.000000 -0.148324  0.148324   \n",
       "\n",
       "          t-test p  vals  \n",
       "129   0.000000e+00     2  \n",
       "106   3.530465e-19     2  \n",
       "71    0.000000e+00     2  \n",
       "72    3.419408e-20     2  \n",
       "73    0.000000e+00     2  \n",
       "113   8.326452e-02     2  \n",
       "111   7.037820e-02     2  \n",
       "133   3.173155e-01     2  \n",
       "83    1.573013e-01     2  \n",
       "84    1.430437e-02     2  \n",
       "86    4.676670e-03     2  \n",
       "89    4.583503e-06     2  \n",
       "90    5.217817e-26     2  \n",
       "93    4.042413e-64     2  \n",
       "94    0.000000e+00     2  \n",
       "97    3.173155e-01     2  \n",
       "98    9.900238e-21     2  \n",
       "108   6.312788e-03     2  \n",
       "118   1.302655e-39     2  \n",
       "121  9.223437e-101     2  \n",
       "70    0.000000e+00     2  \n",
       "138   3.173155e-01     2  \n",
       "126   0.000000e+00     2  \n",
       "14    4.583503e-06     2  \n",
       "15    4.583503e-06     2  \n",
       "16    4.583503e-06     2  \n",
       "18    4.583503e-06     2  \n",
       "20    4.583503e-06     2  \n",
       "26    4.583503e-06     2  \n",
       "29    4.583503e-06     2  \n",
       "62    4.583503e-06     2  \n",
       "130   0.000000e+00     2  \n",
       "51    0.000000e+00     2  \n",
       "43    4.583503e-06     2  \n",
       "123   9.317263e-15     2  \n",
       "50    0.000000e+00     2  \n",
       "52    4.583503e-06     2  \n",
       "105   1.024710e-01     3  \n",
       "145   0.000000e+00     3  \n",
       "127   0.000000e+00     3  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors.sort_values(by=\"vals\").head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a quite a few 2-value factors, it might be worth looking at what proportion of the values for a factor are non-zero overall, and under each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(trainX)\n",
    "l0 = len(trainX0)\n",
    "l1 = len(trainX1)\n",
    "factors[\"nonzero\"] = factors.factor.apply(lambda f: len(trainX.loc[trainX[f]!=0])/l)\n",
    "factors[\"nonzero0\"] = factors.factor.apply(lambda f: len(trainX0.loc[trainX0[f]!=0])/l0)\n",
    "factors[\"nonzero1\"] = factors.factor.apply(lambda f: len(trainX1.loc[trainX1[f]!=0])/l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>mu0</th>\n",
       "      <th>mu1</th>\n",
       "      <th>sigma0</th>\n",
       "      <th>sigma1</th>\n",
       "      <th>rho</th>\n",
       "      <th>absrho</th>\n",
       "      <th>t-test p</th>\n",
       "      <th>vals</th>\n",
       "      <th>nonzero</th>\n",
       "      <th>nonzero0</th>\n",
       "      <th>nonzero1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003210</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>3.173155e-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>133</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003210</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>3.173155e-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004540</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>1.573013e-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005242</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>1.024710e-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>113</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005560</td>\n",
       "      <td>0.005560</td>\n",
       "      <td>8.326452e-02</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005912</td>\n",
       "      <td>0.005912</td>\n",
       "      <td>6.551449e-02</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.007863</td>\n",
       "      <td>0.007863</td>\n",
       "      <td>1.430437e-02</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009080</td>\n",
       "      <td>0.009080</td>\n",
       "      <td>4.676670e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.007129</td>\n",
       "      <td>0.007129</td>\n",
       "      <td>2.637066e-02</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>111</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.018156</td>\n",
       "      <td>0.024015</td>\n",
       "      <td>0.005809</td>\n",
       "      <td>0.005809</td>\n",
       "      <td>7.037820e-02</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.000577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>123</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.024873</td>\n",
       "      <td>0.024873</td>\n",
       "      <td>9.317263e-15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>144</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.026030</td>\n",
       "      <td>0.026030</td>\n",
       "      <td>5.116166e-16</td>\n",
       "      <td>75</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.035814</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>-0.028733</td>\n",
       "      <td>0.028733</td>\n",
       "      <td>3.530465e-19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    factor       mu0       mu1    sigma0    sigma1       rho    absrho  \\\n",
       "97      97  0.000021  0.000000  0.004540  0.000000 -0.003210  0.003210   \n",
       "133    133  0.000021  0.000000  0.004540  0.000000 -0.003210  0.003210   \n",
       "83      83  0.000041  0.000000  0.006420  0.000000 -0.004540  0.004540   \n",
       "105    105  0.000021  0.000000  0.002780  0.000000 -0.005242  0.005242   \n",
       "113    113  0.000026  0.000000  0.003370  0.000000 -0.005560  0.005560   \n",
       "88      88  0.000029  0.000000  0.003466  0.000000 -0.005912  0.005912   \n",
       "84      84  0.000124  0.000000  0.011119  0.000000 -0.007863  0.007863   \n",
       "86      86  0.000165  0.000000  0.012839  0.000000 -0.009080  0.009080   \n",
       "117    117  0.000013  0.000000  0.001288  0.000000 -0.007129  0.007129   \n",
       "111    111  0.000330  0.000577  0.018156  0.024015  0.005809  0.005809   \n",
       "123    123  0.001237  0.000000  0.035143  0.000000 -0.024873  0.024873   \n",
       "144    144  0.000693  0.000000  0.018810  0.000000 -0.026030  0.026030   \n",
       "106    106  0.001482  0.000018  0.035814  0.003934 -0.028733  0.028733   \n",
       "\n",
       "         t-test p  vals   nonzero  nonzero0  nonzero1  \n",
       "97   3.173155e-01     2  0.000010  0.000021  0.000000  \n",
       "133  3.173155e-01     2  0.000010  0.000021  0.000000  \n",
       "83   1.573013e-01     2  0.000021  0.000041  0.000000  \n",
       "105  1.024710e-01     3  0.000031  0.000062  0.000000  \n",
       "113  8.326452e-02     2  0.000031  0.000062  0.000000  \n",
       "88   6.551449e-02     4  0.000062  0.000124  0.000000  \n",
       "84   1.430437e-02     2  0.000062  0.000124  0.000000  \n",
       "86   4.676670e-03     2  0.000082  0.000165  0.000000  \n",
       "117  2.637066e-02     6  0.000082  0.000165  0.000000  \n",
       "111  7.037820e-02     2  0.000453  0.000330  0.000577  \n",
       "123  9.317263e-15     2  0.000618  0.001237  0.000000  \n",
       "144  5.116166e-16    75  0.000824  0.001649  0.000000  \n",
       "106  3.530465e-19     2  0.000866  0.001711  0.000021  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors.sort_values(by=\"nonzero\").loc[factors[\"nonzero\"]<0.001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These factors are extremely sparse, so may be noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/jupyter/env3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression().fit(train[train.columns[:-1]],train[\"155\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9924879436132064"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(train[train.columns[:-1]], train[\"155\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test_imperson_without4n7_balanced_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(col_to_delete,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7348722545943523"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(test[test.columns[:-1]], test[\"155\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 73% accuracy from using all the non-constant columns in a default `sklearn` logistic regression, which includes some regularization.\n",
    "\n",
    "Let's try only the 51 factors with extremely low t-test p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '6', '8', '9', '38', '47', '50', '51', '61', '64', '66', '67',\n",
       "       '68', '70', '71', '72', '73', '75', '76', '77', '79', '80', '82',\n",
       "       '90', '93', '94', '98', '104', '106', '107', '109', '110', '112',\n",
       "       '118', '121', '122', '123', '125', '126', '127', '128', '129',\n",
       "       '130', '140', '141', '142', '143', '144', '145', '146', '154'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowp = factors[factors[\"t-test p\"] < 0.000000001].factor.values\n",
    "lowp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/jupyter/env3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression().fit(train[lowp],train[\"155\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5979630459684248"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(test[lowp],test[\"155\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see if there is a threshold below which we get better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6113850291349171"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def p_threshold_to_lr_score(p):\n",
    "    lowp = factors[factors[\"t-test p\"] < p].factor.values\n",
    "    lr = LogisticRegression(solver=\"liblinear\").fit(train[lowp],train[\"155\"])\n",
    "    return lr.score(test[lowp],test[\"155\"])\n",
    "p_threshold_to_lr_score(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7e8f430048>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ps = [0.5, 0.3, 0.2, 0.1, 0.005, 0.001]\n",
    "ss = [p_threshold_to_lr_score(p) for p in ps]\n",
    "plt.plot(ps,ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe some of the factors with higher p-values are actually better predictors..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression().fit(train[train.columns[:-1]],train[\"155\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.97188982e+00, -2.97188982e+00, -5.70423456e+00,\n",
       "        -5.70423456e+00, -1.22188121e-01, -1.22188121e-01,\n",
       "        -1.22188121e-01, -1.22188121e-01, -1.22188121e-01,\n",
       "        -1.22188121e-01, -1.22188121e-01,  2.03462960e+00,\n",
       "        -1.22188121e-01, -4.11851068e+00, -1.33828724e-01,\n",
       "         1.03891618e+00, -1.16110430e+00, -1.22188121e-01,\n",
       "         4.85871320e+00, -1.22188121e-01, -2.71606819e+00,\n",
       "        -1.93423606e+00, -4.43167205e+00,  3.45810678e+00,\n",
       "        -5.12423306e+00,  5.76116444e+00, -2.53150651e+00,\n",
       "         4.16397375e+00,  6.05664910e-01,  7.85671962e-01,\n",
       "         2.97773819e+00, -2.51923253e+00, -2.38570489e+00,\n",
       "        -1.40349367e-01, -1.02270764e+01, -1.10047661e-04,\n",
       "        -6.62944508e-04, -7.72992169e-04, -6.68604534e-05,\n",
       "        -1.22188121e-01,  4.56870105e+00, -3.74304433e+00,\n",
       "        -7.62789765e+00, -3.29112960e-05,  4.57385972e+00,\n",
       "        -2.57598852e+00, -4.16488299e-04,  1.37102794e-01,\n",
       "        -1.13304933e+01,  2.77876475e-02, -1.46395677e+00,\n",
       "        -9.30267874e-05,  4.36938878e+00,  5.90160411e+00,\n",
       "        -1.18531844e-06, -7.62974392e-05,  1.05543444e+00,\n",
       "        -1.48875217e-01,  3.30699419e+00, -4.29433929e-01,\n",
       "        -1.56353411e+00, -2.41218912e+00, -1.94453263e-02,\n",
       "        -7.13154995e-05, -3.63206863e-02, -1.42185628e-04,\n",
       "        -7.31678501e-05, -4.63087659e+00, -3.29112960e-05,\n",
       "        -1.86129976e+00,  4.24304983e+00, -4.96960603e+00,\n",
       "        -2.69025225e+00, -3.95982366e+00, -3.42704696e-02,\n",
       "        -2.62688373e-02, -2.62688373e-02, -3.94125763e-01]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could look at size of coefficients as an indicator of importance..? Maybe something to pursue. Or could use random forest to get relative importances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like some factors are highly correlated, so perhaps PCA or clustering on factors first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=20, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(train[train.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.02098232, 0.86131361, 0.2540735 , 0.12245628, 0.1020006 ,\n",
       "       0.06261603, 0.03867685, 0.03298436, 0.02661625, 0.02474394,\n",
       "       0.02087587, 0.01080953, 0.0084663 , 0.00714234, 0.00627585,\n",
       "       0.00611999, 0.00459349, 0.0039681 , 0.00341409, 0.00329887])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train = pca.fit_transform(train[train.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/jupyter/env3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression().fit(pca_train,train[\"155\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_test = pca.transform(test[test.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8595049554260671"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(pca_test,test[\"155\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twenty component PCA does relatively well.\n",
    "\n",
    "Let's look at a few more or fewer components. We can do that by taking say fifty and then keeping the first 5, 10, 20, 50 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train = pca.fit_transform(train[train.columns[:-1]])\n",
    "pca_test = pca.transform(test[test.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\t0.8479007918721052\n",
      "5:\t0.9719358533791523\n",
      "10:\t0.9775885253249664\n",
      "20:\t0.8595049554260671\n",
      "50:\t0.8595049554260671\n"
     ]
    }
   ],
   "source": [
    "for pcs in [1,5,10,20,50]:\n",
    "    lr = LogisticRegression(solver='liblinear').fit(pca_train[:,:pcs],train[\"155\"])\n",
    "    score = lr.score(pca_test[:,:pcs], test[\"155\"])\n",
    "    print(f\"{pcs}:\\t{score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking closer at 1 to 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def principalcomponents_lrscore(n):\n",
    "    lr = LogisticRegression(solver='liblinear').fit(pca_train[:,:n],train[\"155\"])\n",
    "    score = lr.score(pca_test[:,:n], test[\"155\"])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs = list(range(1,20))\n",
    "lrs = [principalcomponents_lrscore(n) for n in pcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7e8e8ad828>]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pcs, lrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems 10 is a good choice of principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7e88568470>]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=19)\n",
    "pca.fit(train[train.columns[:-1]])\n",
    "plt.plot(pcs,pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation in logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
