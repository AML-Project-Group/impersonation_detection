{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' PRE-PROCESSING (INDIVIDUAL 1) '''\n",
    "''' Michelangelo Rubino '''\n",
    "\n",
    "# The function preproc_df(filename) at the end of this stage can be used to perform the following transformations:\n",
    "\n",
    "# Step 1 - delete the features with no values\n",
    "# Step 2 - delete the features with duplicated values \n",
    "# Step 3 - remove highly correlated features (kendall/spearman >= 0.9)\n",
    "# Step 4 - standardize the features to give them a distribution closer to the normal one\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from numpy import set_printoptions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# uncomment to show every output rows\n",
    "#pd.set_option('display.max_rows', 200) \n",
    "\n",
    "# uncomment to show every output columns\n",
    "#pd.set_option('display.max_columns', 200) \n",
    "\n",
    "set_printoptions(precision=3) # how the floating numbers are shown\n",
    "\n",
    "''' Load the data from the train dataset and create a dataframe '''\n",
    "\n",
    "filename = 'train_imperson_without4n7_balanced_data.csv'\n",
    "\n",
    "# use the code below to load the test dataset\n",
    "# filename = 'test_imperson_without4n7_balanced_data.csv'\n",
    "\n",
    "df = pd.read_csv(filename,\n",
    "                header=0,\n",
    "                na_values=['nan'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97044 entries, 0 to 97043\n",
      "Columns: 153 entries, 1 to 155\n",
      "dtypes: float64(48), int64(105)\n",
      "memory usage: 113.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "''' View dataframe info '''\n",
    "\n",
    "# the dataframe does not contain null values (it can be verified by using df.isnull().sum())\n",
    "# 97,044 rows, 153 columns\n",
    "# the class is the feature 155\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n",
      "0    48522\n",
      "1    48522\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "''' The observations are perfectly balanced: 50% class 0, 50% class 1 '''\n",
    "class_counts = df.groupby('155').size()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035528</td>\n",
       "      <td>0.035528</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035116</td>\n",
       "      <td>0.035116</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020133</td>\n",
       "      <td>0.020133</td>\n",
       "      <td>0.073203</td>\n",
       "      <td>0.073203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140800</td>\n",
       "      <td>0.140800</td>\n",
       "      <td>0.144440</td>\n",
       "      <td>0.144440</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004916</td>\n",
       "      <td>0.004916</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034137</td>\n",
       "      <td>0.034137</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2  3         5         6         8         9  10  11  12  ...  146  147  \\\n",
       "0  0  0  0  0.000066  0.000066  0.009150  0.009150   0   0   0  ...  0.0    0   \n",
       "1  0  0  0  0.000014  0.000014  0.000000  0.000000   0   0   0  ...  0.0    0   \n",
       "2  0  0  0  0.035528  0.035528  0.070588  0.070588   0   0   0  ...  0.0    0   \n",
       "3  0  0  0  0.005128  0.005128  0.094771  0.094771   0   0   0  ...  0.0    0   \n",
       "4  0  0  0  0.035116  0.035116  0.070588  0.070588   0   0   0  ...  0.0    0   \n",
       "5  0  0  0  0.005099  0.005099  0.094771  0.094771   0   0   0  ...  0.0    0   \n",
       "6  0  0  0  0.020133  0.020133  0.073203  0.073203   0   0   0  ...  0.0    0   \n",
       "7  0  0  0  0.140800  0.140800  0.144440  0.144440   0   0   0  ...  0.0    0   \n",
       "8  0  0  0  0.004916  0.004916  0.094771  0.094771   0   0   0  ...  0.0    0   \n",
       "9  0  0  0  0.034137  0.034137  0.070588  0.070588   0   0   0  ...  0.0    0   \n",
       "\n",
       "   148  149  150  151  152  153  154  155  \n",
       "0    0    0    0    0    0    0  0.0    0  \n",
       "1    0    0    0    0    0    0  0.0    0  \n",
       "2    0    0    0    0    0    0  0.0    0  \n",
       "3    0    0    0    0    0    0  0.0    0  \n",
       "4    0    0    0    0    0    0  0.0    0  \n",
       "5    0    0    0    0    0    0  0.0    0  \n",
       "6    0    0    0    0    0    0  0.0    0  \n",
       "7    0    0    0    0    0    0  0.0    0  \n",
       "8    0    0    0    0    0    0  0.0    0  \n",
       "9    0    0    0    0    0    0  0.0    0  \n",
       "\n",
       "[10 rows x 153 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Check the first 10 rows '''\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             1        2        3             5             6             8  \\\n",
      "count  97044.0  97044.0  97044.0  97044.000000  97044.000000  97044.000000   \n",
      "mean       0.0      0.0      0.0      0.006252      0.006252      0.193837   \n",
      "std        0.0      0.0      0.0      0.015541      0.015541      0.354444   \n",
      "min        0.0      0.0      0.0      0.000003      0.000003      0.000000   \n",
      "25%        0.0      0.0      0.0      0.001442      0.001442      0.037908   \n",
      "50%        0.0      0.0      0.0      0.003706      0.003706      0.037908   \n",
      "75%        0.0      0.0      0.0      0.005916      0.005916      0.054902   \n",
      "max        0.0      0.0      0.0      0.978440      0.978440      1.000000   \n",
      "\n",
      "                  9       10       11       12  ...           146      147  \\\n",
      "count  97044.000000  97044.0  97044.0  97044.0  ...  97044.000000  97044.0   \n",
      "mean       0.193837      0.0      0.0      0.0  ...      0.028436      0.0   \n",
      "std        0.354444      0.0      0.0      0.0  ...      0.062765      0.0   \n",
      "min        0.000000      0.0      0.0      0.0  ...      0.000000      0.0   \n",
      "25%        0.037908      0.0      0.0      0.0  ...      0.000000      0.0   \n",
      "50%        0.037908      0.0      0.0      0.0  ...      0.000000      0.0   \n",
      "75%        0.054902      0.0      0.0      0.0  ...      0.000000      0.0   \n",
      "max        1.000000      0.0      0.0      0.0  ...      1.000000      0.0   \n",
      "\n",
      "           148      149      150      151      152      153           154  \\\n",
      "count  97044.0  97044.0  97044.0  97044.0  97044.0  97044.0  97044.000000   \n",
      "mean       0.0      0.0      0.0      0.0      0.0      0.0      0.178474   \n",
      "std        0.0      0.0      0.0      0.0      0.0      0.0      0.360078   \n",
      "min        0.0      0.0      0.0      0.0      0.0      0.0      0.000000   \n",
      "25%        0.0      0.0      0.0      0.0      0.0      0.0      0.000000   \n",
      "50%        0.0      0.0      0.0      0.0      0.0      0.0      0.023873   \n",
      "75%        0.0      0.0      0.0      0.0      0.0      0.0      0.023873   \n",
      "max        0.0      0.0      0.0      0.0      0.0      0.0      1.000000   \n",
      "\n",
      "                155  \n",
      "count  97044.000000  \n",
      "mean       0.500000  \n",
      "std        0.500003  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        0.500000  \n",
      "75%        1.000000  \n",
      "max        1.000000  \n",
      "\n",
      "[8 rows x 153 columns]\n"
     ]
    }
   ],
   "source": [
    "''' Descriptive statistics '''\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5' '6' '8' '9' '14' '15' '16' '18' '20' '26' '29' '38' '43' '47' '48'\n",
      " '50' '51' '52' '61' '62' '64' '66' '67' '68' '70' '71' '72' '73' '75'\n",
      " '76' '77' '78' '79' '80' '82' '83' '84' '86' '88' '89' '90' '93' '94'\n",
      " '97' '98' '104' '105' '106' '107' '108' '109' '110' '111' '112' '113'\n",
      " '117' '118' '119' '120' '121' '122' '123' '125' '126' '127' '128' '129'\n",
      " '130' '133' '138' '140' '141' '142' '143' '144' '145' '146' '154' '155']\n"
     ]
    }
   ],
   "source": [
    "''' Step 1 - Delete columns with no values '''\n",
    "\n",
    "columnsToDelete = [] \n",
    "\n",
    "# if the feature has std == 0 it means no values or only one value\n",
    "for key, value in df.iteritems():\n",
    "    if df[key].std() == 0:\n",
    "        columnsToDelete.append(key)\n",
    "        \n",
    "df1 = df.drop(columnsToDelete, axis=1) # 74 features have been deleted\n",
    "\n",
    "# the features are now 78 + 1 class\n",
    "print(df1.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5' '8' '14' '38' '47' '48' '50' '51' '61' '64' '66' '67' '68' '70' '71'\n",
      " '72' '73' '75' '76' '77' '78' '79' '80' '82' '83' '84' '86' '88' '90'\n",
      " '93' '94' '97' '98' '104' '105' '106' '107' '108' '109' '110' '111' '112'\n",
      " '113' '117' '118' '119' '120' '121' '122' '123' '125' '126' '127' '128'\n",
      " '129' '130' '138' '140' '141' '142' '143' '144' '145' '154' '155']\n"
     ]
    }
   ],
   "source": [
    "''' Step 2 - Some features are duplicates of other features, then they can be removed keeping only the first column '''\n",
    "\n",
    "# df has 14 duplicated features, then, after removing them, the new dataframe has 64 features + 1 class\n",
    "df2 = df1.loc[:,~df1.T.duplicated(keep='first')]\n",
    "\n",
    "# the features are now 64 + 1 class\n",
    "print(df2.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       8718\n",
      "8        399\n",
      "14         2\n",
      "38     25023\n",
      "47        12\n",
      "48        11\n",
      "50         2\n",
      "51         2\n",
      "61        63\n",
      "64        20\n",
      "66         3\n",
      "67        12\n",
      "68         3\n",
      "70         2\n",
      "71         2\n",
      "72         2\n",
      "73         2\n",
      "75        80\n",
      "76       133\n",
      "77        84\n",
      "78        42\n",
      "79        46\n",
      "80        18\n",
      "82      4096\n",
      "83         2\n",
      "84         2\n",
      "86         2\n",
      "88         4\n",
      "90         2\n",
      "93         2\n",
      "       ...  \n",
      "106        2\n",
      "107     1738\n",
      "108        2\n",
      "109        4\n",
      "110        3\n",
      "111        2\n",
      "112        4\n",
      "113        2\n",
      "117        6\n",
      "118        2\n",
      "119       34\n",
      "120       14\n",
      "121        2\n",
      "122        3\n",
      "123        2\n",
      "125        3\n",
      "126        2\n",
      "127        3\n",
      "128        3\n",
      "129        2\n",
      "130        2\n",
      "138        2\n",
      "140    17320\n",
      "141        4\n",
      "142    20359\n",
      "143     1076\n",
      "144       75\n",
      "145        3\n",
      "154      333\n",
      "155        2\n",
      "Length: 65, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "''' Check the unique values for each feature '''\n",
    "\n",
    "print(df2.nunique()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Plot the distribution for the 3 main groups:\n",
    "\n",
    "    - features with continuous values between 0 and 1 (ex: 38)\n",
    "    - features with only two values, 0 and 1 (ex: 71)\n",
    "    - features with a few values (ex: 145) '''\n",
    "\n",
    "# no feature with a perfect normal distribution\n",
    "df2[[\"38\", \"71\", \"145\"]].plot.kde(figsize=(5,3), sharex=False)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['47', '50', '64', '66', '68', '84', '86', '90', '97', '98', '107', '108', '118', '119', '126', '127', '128', '129', '141']\n"
     ]
    }
   ],
   "source": [
    "''' Step 3 - Create two correlation matrices (Kendall and Spearman) and remove highly correlated features (ie. >= 0.9 )'''\n",
    "\n",
    "# Create correlation matrix with kendall method\n",
    "corr_matrix_kendall = df2.corr(method='kendall').abs()\n",
    "\n",
    "# Create a True/False mask and apply it\n",
    "mask_kendall = np.triu(np.ones_like(corr_matrix_kendall, dtype=bool))\n",
    "tri_df_kendall = corr_matrix_kendall.mask(mask_kendall)\n",
    "\n",
    "# List column names of highly correlated features ( >= 0.90 )\n",
    "kendall_to_drop = [c for c in tri_df_kendall.columns if any(tri_df_kendall[c] >= 0.90)]\n",
    "\n",
    "# Create correlation matrix with spearman method\n",
    "corr_matrix_spearman = df2.corr(method='spearman').abs()\n",
    "\n",
    "# Create a True/False mask and apply it\n",
    "mask_spearman = np.triu(np.ones_like(corr_matrix_spearman, dtype=bool))\n",
    "tri_df_spearman = corr_matrix_spearman.mask(mask_spearman)\n",
    "\n",
    "# List column names of highly correlated features ( >= 0.90 )\n",
    "spearman_to_drop = [c for c in tri_df_spearman.columns if any(tri_df_spearman[c] >= 0.90)]\n",
    "\n",
    "# The two methods show almost the same features, 19 are in common, 1 is not\n",
    "drop_high_corr = []\n",
    "for i in kendall_to_drop:\n",
    "    if i in spearman_to_drop:\n",
    "        drop_high_corr.append(i)\n",
    "\n",
    "# drop the 19 common features with high correlation both with kendall and spearman       \n",
    "df3 = df2.drop(drop_high_corr, axis=1)  \n",
    "\n",
    "# print the common features removed from the dataframe\n",
    "print(drop_high_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "['5' '8' '14' '38' '48' '51' '61' '67' '70' '71' '72' '73' '75' '76' '77'\n",
      " '78' '79' '80' '82' '83' '88' '93' '94' '104' '105' '106' '109' '110'\n",
      " '111' '112' '113' '117' '120' '121' '122' '123' '125' '130' '138' '140'\n",
      " '142' '143' '144' '145' '154' '155']\n"
     ]
    }
   ],
   "source": [
    "''' After this step the dataframe has 45 features and 1 class '''\n",
    "\n",
    "print(len(df3.columns.values))\n",
    "print(df3.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Analysis and plotting of the dataframe df3 show that none of the features has a normal form '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Analysis and plotting of the dataframe df3 show that none of the features has a normal form '''\n",
    "\n",
    "# Uncomment to see the plots\n",
    "\n",
    "# skewness\n",
    "#skew = df3.skew()\n",
    "#print(skew)\n",
    "\n",
    "# histogram plot\n",
    "#df3.hist(layout=(9,9), figsize=(30,14))\n",
    "#pyplot.show()\n",
    "\n",
    "# density plot\n",
    "#df3.plot(kind='density', subplots=True, layout=(9,9), sharex=False, figsize=(20,14))\n",
    "#pyplot.show()\n",
    "\n",
    "# Box and Whisker Plot\n",
    "#df3.plot(kind='box', subplots=True, layout=(9,9), sharex=False, sharey=False, figsize=(20,14))\n",
    "#pyplot.show()\n",
    "\n",
    "# Scatterplot Matrix\n",
    "# it takes a lot to run\n",
    "#scatter_matrix(df3, figsize=[5, 5])\n",
    "#pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Step 4 - Standardize the features to give them a normal form: mean = 0, sd = 1 '''\n",
    "\n",
    "# save the features name\n",
    "features_names = df3.columns.values\n",
    "\n",
    "# use the array lenght\n",
    "df3_len = len(df3.columns.values) - 1\n",
    "\n",
    "# extract the values from the dataframe\n",
    "array = df3.values\n",
    "X = array[:, 0:df3_len] # extract the features\n",
    "Y = array[:, df3_len].astype(int) # extract the class\n",
    "\n",
    "# fit and transform the values\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "\n",
    "# a new dataframe is created with the standardized values\n",
    "df4 = pd.DataFrame(rescaledX, columns=features_names[0:df3_len])\n",
    "\n",
    "# add the class 155\n",
    "df4.insert(df3_len, '155', Y, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          5         8        14        38       48        51        61  \\\n",
      "0 -0.398089 -0.521063  0.014712 -3.142811  0.01475  1.534041  0.708991   \n",
      "1 -0.401396 -0.546879  0.014712 -3.142628  0.01475  1.534041  0.708991   \n",
      "2  1.883791 -0.347726  0.014712 -3.142264  0.01475 -0.651873 -0.254672   \n",
      "3 -0.072373 -0.279498  0.014712 -3.141809  0.01475 -0.651873 -4.109153   \n",
      "4  1.857280 -0.347726  0.014712 -3.141445  0.01475 -0.651873 -0.013756   \n",
      "\n",
      "         67        70        71  ...       125       130      138       140  \\\n",
      "0 -0.175252 -0.285459  1.391247  ... -0.038843 -0.148360 -0.00321 -1.050047   \n",
      "1  1.575793 -0.285459 -0.718780  ... -0.038843 -0.148360 -0.00321 -1.050047   \n",
      "2  0.602982 -0.285459 -0.718780  ... -0.038843 -0.148360 -0.00321 -1.050047   \n",
      "3  0.602982 -0.285459 -0.718780  ... -0.038843  6.740366 -0.00321 -1.050047   \n",
      "4  0.602982 -0.285459 -0.718780  ... -0.038843 -0.148360 -0.00321 -1.050047   \n",
      "\n",
      "        142       143      144       145       154  155  \n",
      "0 -0.995985 -0.091603 -0.02603 -0.453058 -0.495656    0  \n",
      "1 -0.995985 -0.091603 -0.02603 -0.453058 -0.495656    0  \n",
      "2 -0.995985 -0.091603 -0.02603 -0.453058 -0.495656    0  \n",
      "3 -0.995985 -0.091603 -0.02603 -0.453058 -0.495656    0  \n",
      "4 -0.995985 -0.091603 -0.02603 -0.453058 -0.495656    0  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "''' Now we have a dataframe with standardized values '''\n",
    "\n",
    "print(df4.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' After standardizing, the features do not show a perfect bell-shaped distribution, but there\n",
    "    is some improvement '''\n",
    "\n",
    "df4[[\"38\", \"71\", \"145\"]].plot.kde(figsize=(5,3), sharex=False )\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function performs the steps previously described '''\n",
    "\n",
    "filename = 'train_imperson_without4n7_balanced_data.csv'\n",
    "\n",
    "def preproc_df(filename):\n",
    "    dataframe = pd.read_csv(filename, header=0, na_values=['nan'])\n",
    "    \n",
    "    # Step 1 - remove features with no values\n",
    "    columnsToDelete = [] \n",
    "    for key, value in dataframe.iteritems():\n",
    "        if dataframe[key].std() == 0:\n",
    "            columnsToDelete.append(key)\n",
    "        \n",
    "    df1 = dataframe.drop(columnsToDelete, axis=1)\n",
    "    \n",
    "    # Step 2 - remove duplicated features, keeping only the first one \n",
    "    df2 = df1.loc[:,~df1.T.duplicated(keep='first')]\n",
    "    \n",
    "    # Step 3 - Compute correlation matrices and drop the features with high correlation \n",
    "    corr_matrix_kendall = df2.corr(method='kendall').abs()\n",
    "    mask_kendall = np.triu(np.ones_like(corr_matrix_kendall, dtype=bool))\n",
    "    tri_df_kendall = corr_matrix_kendall.mask(mask_kendall)\n",
    "    kendall_to_drop = [c for c in tri_df_kendall.columns if any(tri_df_kendall[c] >= 0.90)]\n",
    "\n",
    "    corr_matrix_spearman = df2.corr(method='spearman').abs()\n",
    "    mask_spearman = np.triu(np.ones_like(corr_matrix_spearman, dtype=bool))\n",
    "    tri_df_spearman = corr_matrix_spearman.mask(mask_spearman)\n",
    "    spearman_to_drop = [c for c in tri_df_spearman.columns if any(tri_df_spearman[c] >= 0.90)]\n",
    "    \n",
    "    # list the features having high kendall and spearman correlation\n",
    "    drop_high_corr = []\n",
    "    for i in kendall_to_drop:\n",
    "        if i in spearman_to_drop:\n",
    "            drop_high_corr.append(i)\n",
    "\n",
    "    # drop the common features       \n",
    "    df3 = df2.drop(drop_high_corr, axis=1)  \n",
    "    \n",
    "    # Step 4 - Standardize the features\n",
    "    features_names = df3.columns.values # save the feature names\n",
    "    df3_len = len(df3.columns.values) - 1 # use the array length \n",
    "\n",
    "    # extract the values from the dataframe (features and class)\n",
    "    array = df3.values\n",
    "    X = array[:, 0:df3_len] \n",
    "    Y = array[:, df3_len].astype(int) \n",
    "\n",
    "    # fit and transform the values\n",
    "    scaler = StandardScaler().fit(X)\n",
    "    rescaledX = scaler.transform(X)\n",
    "\n",
    "    # a new dataframe is created with the standardized values\n",
    "    df4 = pd.DataFrame(rescaledX, columns=features_names[0:df3_len])\n",
    "\n",
    "    # add the class 155\n",
    "    df4.insert(df3_len, '155', Y, False)\n",
    "\n",
    "    return df4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Before the Feature selection stage the train dataset has 45 features and 1 class\\n\\n['5' '8' '14' '38' '48' '51' '61' '67' '70' '71' '72' '73' '75' '76' '77'\\n '78' '79' '80' '82' '83' '88' '93' '94' '104' '105' '106' '109' '110'\\n '111' '112' '113' '117' '120' '121' '122' '123' '125' '130' '138' '140'\\n '142' '143' '144' '145' '154' '155']\\n\\n\\nwhile the test dataset has 43 features and 1 class\\n\\n['5' '8' '14' '38' '47' '48' '51' '61' '64' '67' '70' '71' '72' '73' '75'\\n '76' '77' '79' '80' '81' '82' '94' '104' '105' '106' '109' '110' '111'\\n '112' '120' '121' '122' '123' '125' '128' '140' '141' '142' '143' '144'\\n '145' '148' '154' '155']\\n \\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Before the Feature selection stage the train dataset has 45 features and 1 class\n",
    "\n",
    "['5' '8' '14' '38' '48' '51' '61' '67' '70' '71' '72' '73' '75' '76' '77'\n",
    " '78' '79' '80' '82' '83' '88' '93' '94' '104' '105' '106' '109' '110'\n",
    " '111' '112' '113' '117' '120' '121' '122' '123' '125' '130' '138' '140'\n",
    " '142' '143' '144' '145' '154' '155']\n",
    "\n",
    "\n",
    "while the test dataset has 43 features and 1 class\n",
    "\n",
    "['5' '8' '14' '38' '47' '48' '51' '61' '64' '67' '70' '71' '72' '73' '75'\n",
    " '76' '77' '79' '80' '81' '82' '94' '104' '105' '106' '109' '110' '111'\n",
    " '112' '120' '121' '122' '123' '125' '128' '140' '141' '142' '143' '144'\n",
    " '145' '148' '154' '155']\n",
    " \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Feature Selection (INDIVIDUAL 2) '''\n",
    "''' Ian Dickerson '''\n",
    "from sklearn.feature_selection import mutual_info_classif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>8</th>\n",
       "      <th>14</th>\n",
       "      <th>38</th>\n",
       "      <th>48</th>\n",
       "      <th>51</th>\n",
       "      <th>61</th>\n",
       "      <th>67</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>...</th>\n",
       "      <th>125</th>\n",
       "      <th>130</th>\n",
       "      <th>138</th>\n",
       "      <th>140</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.398089</td>\n",
       "      <td>-0.521063</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>-3.142811</td>\n",
       "      <td>0.01475</td>\n",
       "      <td>1.534041</td>\n",
       "      <td>0.708991</td>\n",
       "      <td>-0.175252</td>\n",
       "      <td>-0.285459</td>\n",
       "      <td>1.391247</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038843</td>\n",
       "      <td>-0.148360</td>\n",
       "      <td>-0.00321</td>\n",
       "      <td>-1.050047</td>\n",
       "      <td>-0.995985</td>\n",
       "      <td>-0.091603</td>\n",
       "      <td>-0.02603</td>\n",
       "      <td>-0.453058</td>\n",
       "      <td>-0.495656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.401396</td>\n",
       "      <td>-0.546879</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>-3.142628</td>\n",
       "      <td>0.01475</td>\n",
       "      <td>1.534041</td>\n",
       "      <td>0.708991</td>\n",
       "      <td>1.575793</td>\n",
       "      <td>-0.285459</td>\n",
       "      <td>-0.718780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038843</td>\n",
       "      <td>-0.148360</td>\n",
       "      <td>-0.00321</td>\n",
       "      <td>-1.050047</td>\n",
       "      <td>-0.995985</td>\n",
       "      <td>-0.091603</td>\n",
       "      <td>-0.02603</td>\n",
       "      <td>-0.453058</td>\n",
       "      <td>-0.495656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.883791</td>\n",
       "      <td>-0.347726</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>-3.142264</td>\n",
       "      <td>0.01475</td>\n",
       "      <td>-0.651873</td>\n",
       "      <td>-0.254672</td>\n",
       "      <td>0.602982</td>\n",
       "      <td>-0.285459</td>\n",
       "      <td>-0.718780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038843</td>\n",
       "      <td>-0.148360</td>\n",
       "      <td>-0.00321</td>\n",
       "      <td>-1.050047</td>\n",
       "      <td>-0.995985</td>\n",
       "      <td>-0.091603</td>\n",
       "      <td>-0.02603</td>\n",
       "      <td>-0.453058</td>\n",
       "      <td>-0.495656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.072373</td>\n",
       "      <td>-0.279498</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>-3.141809</td>\n",
       "      <td>0.01475</td>\n",
       "      <td>-0.651873</td>\n",
       "      <td>-4.109153</td>\n",
       "      <td>0.602982</td>\n",
       "      <td>-0.285459</td>\n",
       "      <td>-0.718780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038843</td>\n",
       "      <td>6.740366</td>\n",
       "      <td>-0.00321</td>\n",
       "      <td>-1.050047</td>\n",
       "      <td>-0.995985</td>\n",
       "      <td>-0.091603</td>\n",
       "      <td>-0.02603</td>\n",
       "      <td>-0.453058</td>\n",
       "      <td>-0.495656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.857280</td>\n",
       "      <td>-0.347726</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>-3.141445</td>\n",
       "      <td>0.01475</td>\n",
       "      <td>-0.651873</td>\n",
       "      <td>-0.013756</td>\n",
       "      <td>0.602982</td>\n",
       "      <td>-0.285459</td>\n",
       "      <td>-0.718780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038843</td>\n",
       "      <td>-0.148360</td>\n",
       "      <td>-0.00321</td>\n",
       "      <td>-1.050047</td>\n",
       "      <td>-0.995985</td>\n",
       "      <td>-0.091603</td>\n",
       "      <td>-0.02603</td>\n",
       "      <td>-0.453058</td>\n",
       "      <td>-0.495656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          5         8        14        38       48        51        61  \\\n",
       "0 -0.398089 -0.521063  0.014712 -3.142811  0.01475  1.534041  0.708991   \n",
       "1 -0.401396 -0.546879  0.014712 -3.142628  0.01475  1.534041  0.708991   \n",
       "2  1.883791 -0.347726  0.014712 -3.142264  0.01475 -0.651873 -0.254672   \n",
       "3 -0.072373 -0.279498  0.014712 -3.141809  0.01475 -0.651873 -4.109153   \n",
       "4  1.857280 -0.347726  0.014712 -3.141445  0.01475 -0.651873 -0.013756   \n",
       "\n",
       "         67        70        71  ...       125       130      138       140  \\\n",
       "0 -0.175252 -0.285459  1.391247  ... -0.038843 -0.148360 -0.00321 -1.050047   \n",
       "1  1.575793 -0.285459 -0.718780  ... -0.038843 -0.148360 -0.00321 -1.050047   \n",
       "2  0.602982 -0.285459 -0.718780  ... -0.038843 -0.148360 -0.00321 -1.050047   \n",
       "3  0.602982 -0.285459 -0.718780  ... -0.038843  6.740366 -0.00321 -1.050047   \n",
       "4  0.602982 -0.285459 -0.718780  ... -0.038843 -0.148360 -0.00321 -1.050047   \n",
       "\n",
       "        142       143      144       145       154  155  \n",
       "0 -0.995985 -0.091603 -0.02603 -0.453058 -0.495656    0  \n",
       "1 -0.995985 -0.091603 -0.02603 -0.453058 -0.495656    0  \n",
       "2 -0.995985 -0.091603 -0.02603 -0.453058 -0.495656    0  \n",
       "3 -0.995985 -0.091603 -0.02603 -0.453058 -0.495656    0  \n",
       "4 -0.995985 -0.091603 -0.02603 -0.453058 -0.495656    0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = preproc_df(\"./train_imperson_without4n7_balanced_data.csv\")\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "\n",
    "Build a separate dataframe to track information about the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(index = processed_df.columns[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"MI\"] = mutual_info_classif(processed_df.iloc[:,:-1],processed_df[\"155\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"absrho\"] = [abs(processed_df[f].corr(processed_df[\"155\"],method='pearson' )) for f in features.index]\n",
    "features[\"abstau\"] = [abs(processed_df[f].corr(processed_df[\"155\"],method='kendall' )) for f in features.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the features with high MI, rho or tau can be identified with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI</th>\n",
       "      <th>absrho</th>\n",
       "      <th>abstau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.446103</td>\n",
       "      <td>0.058410</td>\n",
       "      <td>0.517106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.635981</td>\n",
       "      <td>0.438183</td>\n",
       "      <td>0.119957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.648695</td>\n",
       "      <td>0.496848</td>\n",
       "      <td>0.448580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.275384</td>\n",
       "      <td>0.651828</td>\n",
       "      <td>0.651828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.476068</td>\n",
       "      <td>0.838937</td>\n",
       "      <td>0.783199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.319016</td>\n",
       "      <td>0.708561</td>\n",
       "      <td>0.708561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.131529</td>\n",
       "      <td>0.477183</td>\n",
       "      <td>0.477183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.274798</td>\n",
       "      <td>0.296245</td>\n",
       "      <td>0.620754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.478523</td>\n",
       "      <td>0.099870</td>\n",
       "      <td>0.747373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.488204</td>\n",
       "      <td>0.201783</td>\n",
       "      <td>0.289967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.525573</td>\n",
       "      <td>0.081860</td>\n",
       "      <td>0.725743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.154528</td>\n",
       "      <td>0.030155</td>\n",
       "      <td>0.452988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.582380</td>\n",
       "      <td>0.493602</td>\n",
       "      <td>0.234276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.577050</td>\n",
       "      <td>0.180674</td>\n",
       "      <td>0.245990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.575847</td>\n",
       "      <td>0.115751</td>\n",
       "      <td>0.230346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.140865</td>\n",
       "      <td>0.453058</td>\n",
       "      <td>0.453468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.525952</td>\n",
       "      <td>0.434536</td>\n",
       "      <td>0.006752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MI    absrho    abstau\n",
       "5    0.446103  0.058410  0.517106\n",
       "8    0.635981  0.438183  0.119957\n",
       "38   0.648695  0.496848  0.448580\n",
       "51   0.275384  0.651828  0.651828\n",
       "67   0.476068  0.838937  0.783199\n",
       "71   0.319016  0.708561  0.708561\n",
       "73   0.131529  0.477183  0.477183\n",
       "75   0.274798  0.296245  0.620754\n",
       "76   0.478523  0.099870  0.747373\n",
       "77   0.488204  0.201783  0.289967\n",
       "79   0.525573  0.081860  0.725743\n",
       "80   0.154528  0.030155  0.452988\n",
       "82   0.582380  0.493602  0.234276\n",
       "140  0.577050  0.180674  0.245990\n",
       "142  0.575847  0.115751  0.230346\n",
       "145  0.140865  0.453058  0.453468\n",
       "154  0.525952  0.434536  0.006752"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.loc[(features.MI > 0.4)|(features.absrho > 0.4)|(features.abstau > 0.4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "pcaX = pca.fit_transform(processed_df.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the PCs to the processed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_with_pcs = pd.DataFrame(pcaX,columns=[f\"PC{i}\" for i in range(1,6)]).join(processed_df)\n",
    "processed_with_pcs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(filename, rho=0.4, tau=0.4, mi=0.4, pcs=5):\n",
    "    \n",
    "    # Preprocessing\n",
    "    processed_data = preproc_df(filename)\n",
    "    # Feature information tracking\n",
    "    features = pd.DataFrame(index = processed_data.columns[:-1])\n",
    "    features[\"MI\"] = mutual_info_classif(processed_data.iloc[:,:-1],processed_data[\"155\"])\n",
    "    features[\"absrho\"] = [abs(processed_data[f].corr(processed_data[\"155\"],method='pearson' )) for f in features.index]\n",
    "    features[\"abstau\"] = [abs(processed_data[f].corr(processed_data[\"155\"],method='kendall' )) for f in features.index]\n",
    "    # Principal component analysis\n",
    "    pca = PCA(n_components=pcs)\n",
    "    pcaX = pca.fit_transform(processed_data.iloc[:,:-1])\n",
    "    pc_names = [f\"PC{i}\" for i in range(1,pcs+1)]\n",
    "    # Select features that meet the thresholds, plus PCs\n",
    "    feature_names = list(features.loc[(features.MI > mi)|(features.absrho > rho)|(features.abstau > tau)].index)\n",
    "    return pd.DataFrame(pcaX,columns=pc_names).join(processed_data[feature_names+[\"155\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_for_training = get_df(\"./train_imperson_without4n7_balanced_data.csv\")\n",
    "data_for_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' PRE-PROCESSING (INDIVIDUAL 3) '''\n",
    "''' Timothy Chan '''\n",
    "\n",
    "'''Import Models and create the training sets'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X = data_for_training.iloc[:,:-1]\n",
    "y = data_for_training.iloc[:,-1]\n",
    "\n",
    "columnnames = list(data_for_training)\n",
    "\n",
    "\n",
    "##Creates training and test data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25) #75% training data, 25% test data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create initial randomforest model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12062     1]\n",
      " [    2 12196]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12063\n",
      "           1       1.00      1.00      1.00     12198\n",
      "\n",
      "    accuracy                           1.00     24261\n",
      "   macro avg       1.00      1.00      1.00     24261\n",
      "weighted avg       1.00      1.00      1.00     24261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Create model with 1000 trees to start. This includes bagging. Set bootstrap = False to turn off\n",
    "\n",
    "randf = RandomForestClassifier(n_estimators = 100, random_state = 22)\n",
    "randf.fit(X_train, y_train)\n",
    "\n",
    "yhat = randf.predict(X_test)\n",
    "\n",
    "\n",
    "#Metrics and variable importance\n",
    "print(confusion_matrix(y_test,yhat))\n",
    "print(classification_report(y_test,yhat))\n",
    "\n",
    "##Nothing really stands out...We get very good accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR RANDOM FOREST \n",
      "\n",
      "[[12059     4]\n",
      " [   15 12183]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12063\n",
      "           1       1.00      1.00      1.00     12198\n",
      "\n",
      "    accuracy                           1.00     24261\n",
      "   macro avg       1.00      1.00      1.00     24261\n",
      "weighted avg       1.00      1.00      1.00     24261\n",
      "\n",
      "RANDOMFOREST FEATURE IMPORTANCE \n",
      "\n",
      "[('67', 0.1385973608753008), ('76', 0.13304610979837894), ('79', 0.12426580707348343), ('PC2', 0.10963698137094252), ('38', 0.09624454648768453), ('5', 0.0706424332832176), ('71', 0.05241685809707678), ('75', 0.03914839011073828), ('77', 0.035912337648599614), ('80', 0.03523772260562352), ('82', 0.033052777069605375), ('PC3', 0.023770817898767276), ('8', 0.022435806800451562), ('PC1', 0.01798056423184889), ('73', 0.012655502655817854), ('51', 0.011329720080562563), ('142', 0.010826372670798575), ('140', 0.009896512222561321), ('PC4', 0.009673081688855584), ('PC5', 0.008669624803227787), ('154', 0.004547367529154063), ('145', 1.3304997303250559e-05)]\n"
     ]
    }
   ],
   "source": [
    "##Let's limit the depth to 6\n",
    "\n",
    "\n",
    "randfs = RandomForestClassifier(n_estimators = 100, random_state = 22, max_depth=6 )\n",
    "\n",
    "randfs.fit(X_train, y_train)\n",
    "\n",
    "yhats = randfs.predict(X_test)\n",
    "\n",
    "##Results Metrics\n",
    "\n",
    "print(\"RESULTS FOR RANDOM FOREST \\n\")\n",
    "print(confusion_matrix(y_test,yhats))\n",
    "print(classification_report(y_test,yhats))\n",
    "LRimportance = [(feature,importance) for feature, importance in zip(columnnames,randfs.feature_importances_)]\n",
    "LRimportance.sort(key = lambda x:x[1], reverse=True) #returns a list of most important features\n",
    "\n",
    "print(\"RANDOMFOREST FEATURE IMPORTANCE \\n\")\n",
    "print(LRimportance)\n",
    "\n",
    "\n",
    "##19 misclassficiations very good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Linear Logistic Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\timot\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\timot\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LOGISTIC REGRESSION \n",
      "\n",
      "[[11770   293]\n",
      " [  211 11987]]\n",
      " LR Accuracy: 0.9792259181402251\n",
      "LR Precision: 0.9761400651465798\n",
      "LR Recall: 0.9827020823085751\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=0)\n",
    "\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "yhat= logreg.predict(X_test)\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, yhat)\n",
    "\n",
    "print(\"RESULTS FOR LOGISTIC REGRESSION \\n\")\n",
    "\n",
    "print(cnf_matrix)\n",
    "\n",
    "\n",
    "print(\" LR Accuracy:\",metrics.accuracy_score(y_test, yhat))\n",
    "print(\"LR Precision:\",metrics.precision_score(y_test, yhat))\n",
    "print(\"LR Recall:\",metrics.recall_score(y_test, yhat))\n",
    "\n",
    "\n",
    "feature_importance = abs(logreg.coef_[0])\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "\n",
    "featfig = plt.figure()\n",
    "featax = featfig.add_subplot(1, 1, 1)\n",
    "featax.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "featax.set_yticks(pos)\n",
    "featax.set_yticklabels(np.array(X.columns)[sorted_idx], fontsize=8)\n",
    "featax.set_xlabel('Relative Feature Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "##Large number of misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "##Create an ROC curve. ROC score is high 0.99. Seems classifer is good.\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create K-NN model. With Euclidean distance and 5 neighbours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR KNN K=5 \n",
      "\n",
      "[[12036    27]\n",
      " [    4 12194]]\n",
      " KNN #3 Accuracy: 0.9987222290919583\n",
      "KNN #3 Precision: 0.997790688159725\n",
      "KNN #3 Recall: 0.9996720773897361\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Fit\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "#Predict\n",
    "\n",
    "knnpredict = knn.predict(X_test)\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, knnpredict)\n",
    "\n",
    "\n",
    "print(\"RESULTS FOR KNN K=5 \\n\")\n",
    "print(cnf_matrix)\n",
    "\n",
    "\n",
    "print(\" KNN #3 Accuracy:\",metrics.accuracy_score(y_test, knnpredict))\n",
    "print(\"KNN #3 Precision:\",metrics.precision_score(y_test, knnpredict))\n",
    "print(\"KNN #3 Recall:\",metrics.recall_score(y_test, knnpredict))\n",
    "\n",
    "##Very good accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network with 2 layers with 5 Neurons. 1000 iterations of backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12044    19]\n",
      " [    6 12192]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12063\n",
      "           1       1.00      1.00      1.00     12198\n",
      "\n",
      "    accuracy                           1.00     24261\n",
      "   macro avg       1.00      1.00      1.00     24261\n",
      "weighted avg       1.00      1.00      1.00     24261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(5, 5), max_iter=1000) #two layers of 5 neurons, 1000 of backprop\n",
    "mlp.fit(X_train, y_train.values.ravel()) #train the algo\n",
    "\n",
    "predictions = mlp.predict(X_test) #make predictions on the xtest set\n",
    "\n",
    "print(confusion_matrix(y_test,predictions)) #results are good\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with RBF kernel, gamma = 1/n, and relatively low Cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12035    28]\n",
      " [   12 12186]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12063\n",
      "           1       1.00      1.00      1.00     12198\n",
      "\n",
      "    accuracy                           1.00     24261\n",
      "   macro avg       1.00      1.00      1.00     24261\n",
      "weighted avg       1.00      1.00      1.00     24261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='rbf',gamma='auto',C=1)\n",
    "svclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Cosmin Stanciu '"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' PRE-PROCESSING (INDIVIDUAL 4) '''\n",
    "''' Cosmin Stanciu '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' PRE-PROCESSING (INDIVIDUAL 5) '''\n",
    "''' Mike Jun Ming'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
